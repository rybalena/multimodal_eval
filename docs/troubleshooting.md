# Troubleshooting Guide 

This guide lists common issues and fixes when running the framework.

---

## âš™ï¸ Installation

- **Error: `ModuleNotFoundError`**  
  â†’ Ensure installation was done correctly:  
  ```bash
  pip install -e .
  ```

- **Wrong Python version**  
  â†’ Requires Python â‰¥ 3.9.  
  Check with:  
  ```bash
  python --version
  ```

---

## ğŸ¤– Ollama & Models

- **`ollama: command not found`**  
  â†’ Install Ollama from [ollama.com/download](https://ollama.com/download).  
  â†’ Make sure the Ollama server is running.

- **Model not found (LLaVA / Qwen)**  
  â†’ Pull the model manually:  
  ```bash
  ollama run llava:13b
  ollama run qwen2-vl:7b
  ```

---

## ğŸ”‘ OpenAI API

- **Error: `OPENAI_API_KEY not found`**  
  â†’ Add to `.env` file at project root:  
  ```bash
  OPENAI_API_KEY=sk-xxxx
  ```

- **Rate limit exceeded**  
  â†’ Check your OpenAI account quota or switch to Ollama models.

---

## ğŸ“‚ Datasets

- **`FileNotFoundError: dataset not found`**  
  â†’ Verify that dataset files exist in:  
  ```
  data_sets/labeled_data/<task>/...
  data_sets/unlabeled_data/<task>/...
  ```  
  â†’ Labeled (Ground Truth) datasets require ground truth JSON.  
  â†’ Unlabeled datasets can be evaluated only with LLM-as-a-Judge.

- **Invalid JSON format**  
  â†’ Validate with:  
  ```bash
  python -m json.tool your_dataset.json
  ```

- **Mismatch between task and dataset type**  
  â†’ Example: VQA only supports **Labeled** datasets, not Unlabeled.  

---

## ğŸ“Š Results

- **`results/all_runs.csv` is empty**  
  â†’ Likely the model produced no predictions.  
  â†’ Check task-specific logs in `results/<labeled_data|unlabeled_data>/<task>/`.

- **Metrics missing from results**  
  â†’ Ensure dataset type supports metrics:  
    - **Labeled** â†’ full metrics (CIDEr, CLIP, Semantic, etc.)  
    - **Unlabeled** â†’ LLM judge only.

---

## ğŸ› Streamlit

- **Error: `No module named streamlit`**  
  â†’ Install with:  
  ```bash
  pip install streamlit
  ```

- **UI does not launch**  
  â†’ Correct command:  
  ```bash
  streamlit run app_ui/streamlit_ui/streamlit_app.py
  ```

---

## ğŸ“ Tips

- Always activate your virtual environment:  
  ```bash
  source .venv/bin/activate
  ```

- For debugging, print help:  
  ```bash
  python -m multimodal_eval.cli.main --help
  ```

- If GPU is unavailable, Torch falls back to CPU (slower).  
- Check dataset JSON format against [docs/user-guide/tasks.md](user-guide/tasks.md).  

---
